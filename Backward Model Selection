import pandas as pd
import numpy as np
import statsmodels.api as sm
from sklearn.datasets import make_regression

# Generate sample dataset
X_data, y_data = make_regression(n_samples=100, n_features=5, noise=0.1, random_state=42)
X = pd.DataFrame(X_data, columns=[f"Feature_{i}" for i in range(1, 6)])
y = pd.Series(y_data)

def backward_elimination(X, y):
    selected_features = list(X.columns)
    best_models = []
    
    while len(selected_features) > 0:
        X_selected = sm.add_constant(X[selected_features])
        model = sm.OLS(y, X_selected).fit()
        
        # Get the worst p-value (excluding intercept)
        worst_pval = model.pvalues[1:].max()
        
        if worst_pval > 0.05:  # Remove variable with highest p-value
            worst_feature = model.pvalues[1:].idxmax()
            selected_features.remove(worst_feature)
            best_models.append((selected_features[:], model.aic))
        else:
            break

    # Return the last valid model or the full model if no elimination occurred
    return best_models[-1] if best_models else (selected_features, model.aic)

# Run backward elimination
best_model = backward_elimination(X, y)

# Print results
print("Best Features:", best_model[0])
print("AIC Score:", best_model[1])
