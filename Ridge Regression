import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import Ridge, LinearRegression
from sklearn.datasets import make_regression

# Create a synthetic regression dataset with 100 samples and 5 features
X, y = make_regression(n_samples=100, n_features=5, noise=10, random_state=42)

# Fit an ordinary least squares (OLS) model for comparison
ols = LinearRegression().fit(X, y)
ols_coefs = ols.coef_
print("OLS Coefficients:", ols_coefs)

# Define a range of alpha values (regularization strength)
alphas = [0, 0.1, 1, 10, 100]
ridge_coefs = {}

# Fit ridge regression for each alpha value and store the coefficients
for alpha in alphas:
    ridge = Ridge(alpha=alpha, fit_intercept=True)
    ridge.fit(X, y)
    ridge_coefs[alpha] = ridge.coef_
    print(f"Ridge Coefficients with alpha={alpha}: {ridge.coef_}")

# Plotting the coefficients as a function of alpha (on a log scale)
plt.figure(figsize=(8,6))
for feature_idx in range(X.shape[1]):
    # Extract coefficient values for each feature across alphas
    coef_values = [ridge_coefs[alpha][feature_idx] for alpha in alphas]
    plt.plot(alphas, coef_values, marker='o', label=f'Feature {feature_idx}')
    
plt.xscale('log')
plt.xlabel('alpha (regularization strength)')
plt.ylabel('Coefficient Value')
plt.title('Ridge Regression Coefficients vs. Alpha')
plt.legend()
plt.show()
